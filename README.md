# ğŸ¨ **Img2vid-Br-Front-End** ğŸ¨

ğŸš€ **Transforme Imagens em VÃ­deos com Facilidade!** ğŸ¥

ğŸ” **Explore o Poder da IA Generativa** ğŸ¤–

---

ğŸŒŸ **Projeto**: Img2vid-Br-Front-End  
ğŸ”§ **Tecnologia**: Gradio, Stable Video Diffusion  
ğŸ¯ **Objetivo**: Fornecer uma interface intuitiva para gerar vÃ­deos a partir de imagens  
ğŸŒ **InspiraÃ§Ã£o**: Comunidade Hugging Face  
ğŸ’» **Hardware**: Testado em RTX 2060 de 12GB  


**Bem-vindo ao projeto "Gerador de VÃ­deo com Stable Video Diffusion"!** Aqui, eu desenvolvi uma interface **front-end** intuitiva e poderosa utilizando **Gradio** para facilitar o uso e os testes com o modelo **Img2Vid** da **Stability AI**. Meu objetivo foi criar uma ferramenta acessÃ­vel para gerar vÃ­deos a partir de imagens, aproveitando o potencial de IA generativa avanÃ§ada. ğŸš€

## ğŸš€ Exemplo de Imagem EstÃ¡tica de Foguete 

## ğŸ–¼ï¸ Exemplo de Capacidade do Modelo Stability-AI Img2Vid

![Capacidade do Modelo Stability-AI Img2Vid](https://github.com/chaos4455/Img2vid-Br-Front-End/blob/main/assets/chrome_qB6sC8rtiG.png?raw=true)

*Esta imagem Ã© um exemplo do que o modelo Stable Video Diffusion da Stability AI pode fazer, transformando uma imagem estÃ¡tica em uma animaÃ§Ã£o fluida.*


![Exemplo de Foguete EstÃ¡tico](https://github.com/chaos4455/Img2vid-Br-Front-End/blob/main/assets/rocket.png?raw=true)

*Uma imagem simples de um foguete antes da animaÃ§Ã£o. Esta imagem estÃ¡tica foi utilizada como entrada para o modelo.*


## ğŸï¸ Resultado da AnimaÃ§Ã£o do Foguete (Fonte: Stability AI)

![Resultado da AnimaÃ§Ã£o do Foguete](https://github.com/chaos4455/Img2vid-Br-Front-End/blob/main/assets/output_rocket_with_conditions.gif?raw=true)

*Resultado da animaÃ§Ã£o gerada a partir da imagem estÃ¡tica do foguete. Este exemplo foi baseado no paper oficial da Stability AI.*


## ğŸ–¥ï¸ Print da Minha Interface

![Minha Interface](https://github.com/chaos4455/Img2vid-Br-Front-End/blob/main/assets/chrome_qB6sC8rtiG.png?raw=true)

*Aqui estÃ¡ a interface do meu projeto, que foi desenvolvida para facilitar o uso e a experimentaÃ§Ã£o com o modelo img2vid.*


## ğŸ“Š GrÃ¡fico de Consumo de Hardware no Meu PC

![GrÃ¡fico de Consumo de Hardware](https://github.com/chaos4455/Img2vid-Br-Front-End/blob/main/assets/Taskmgr_3CMUvRFKUC.png?raw=true)

*GrÃ¡fico de monitoramento de recursos no meu PC durante a execuÃ§Ã£o do modelo img2vid. Como vocÃª pode ver, o consumo de GPU e CPU Ã© significativo, especialmente para placas abaixo de uma 4090.*

---

## ğŸ’¡ VisÃ£o Geral do Projeto

Este projeto foi inspirado por vÃ¡rios exemplos impressionantes da comunidade **Hugging Face**, como:
- **[Stable Video Diffusion Upscale](https://huggingface.co/spaces/asahi417/stable-video-diffusion-upscale)**: uma abordagem incrÃ­vel para a criaÃ§Ã£o de vÃ­deos de alta qualidade usando difusÃ£o.
- **[AnimateLCM-SVD](https://huggingface.co/spaces/wangfuyun/AnimateLCM-SVD)**: uma aplicaÃ§Ã£o inovadora que anima imagens com detalhes realistas.
- 
## ğŸ–¥ï¸ Exemplo da Interface do RepositÃ³rio de InspiraÃ§Ã£o 1

![Interface do RepositÃ³rio de InspiraÃ§Ã£o 1](https://github.com/chaos4455/Img2vid-Br-Front-End/blob/main/assets/chrome_thPz0v6TcW.png?raw=true)

*Este print mostra a interface de um dos repositÃ³rios que me serviu de inspiraÃ§Ã£o para este projeto.*

## ğŸ–¥ï¸ Print do Projeto 2 que Me Inspirou

![Projeto de InspiraÃ§Ã£o 2](https://github.com/chaos4455/Img2vid-Br-Front-End/blob/main/assets/chrome_bV3oUJhC5J.png?raw=true)

*Este Ã© um print de outro projeto que me inspirou na criaÃ§Ã£o deste front-end.*


Com esses exemplos em mente, decidi construir minha prÃ³pria versÃ£o que oferece uma experiÃªncia simplificada para usuÃ¡rios que desejam explorar as capacidades dos modelos de difusÃ£o. ğŸ˜

---

## ğŸ–¼ï¸ CaracterÃ­sticas do Projeto

Este projeto permite que vocÃª:

- **Carregue uma imagem** e a processe com facilidade.
- **Ajuste parÃ¢metros avanÃ§ados** como nÃºmero de frames, FPS, tamanho do chunk de decodificaÃ§Ã£o, e intensidade de ruÃ­do para gerar vÃ­deos personalizados. ğŸ›ï¸
- **Visualize uma prÃ©via** da imagem selecionada e do vÃ­deo gerado diretamente na interface.
- **Salve automaticamente** o vÃ­deo gerado na raiz do projeto. ğŸ’¾

### Modelos CompatÃ­veis:
- **[stabilityai/stable-video-diffusion-img2vid-xt](https://huggingface.co/stabilityai/stable-video-diffusion-img2vid-xt)**: Recomendado para placas de vÃ­deo como **RTX 4090** ou GPUs de alto desempenho. âš™ï¸
- **[stabilityai/stable-video-diffusion-img2vid](https://huggingface.co/stabilityai/stable-video-diffusion-img2vid)**: Ideal para placas de vÃ­deo como **RTX 3060** ou inferiores. ğŸ’»

---

## âš™ï¸ Tecnologias Utilizadas

- **Python**: Linguagem de programaÃ§Ã£o principal do projeto. ğŸ
- **Gradio**: Utilizado para criar a interface front-end interativa. ğŸŒ
- **Stable Video Diffusion Pipeline**: Modelo de IA que realiza a difusÃ£o para criaÃ§Ã£o de vÃ­deos. ğŸï¸
- **PIL (Python Imaging Library)**: Para manipulaÃ§Ã£o e redimensionamento de imagens. ğŸ–¼ï¸
- **Torch**: Biblioteca usada para a manipulaÃ§Ã£o de tensores e execuÃ§Ã£o de cÃ¡lculos em GPUs. ğŸš€

### ğŸ“¦ DependÃªncias e InstalaÃ§Ã£o:

Certifique-se de ter o **Python** instalado. Em seguida, instale as bibliotecas necessÃ¡rias com o comando:

```bash
pip install torch diffusers gradio pillow
```

## ğŸ¥ VÃ­deo Gerado com o Resultado no Meu PC

![VÃ­deo Gerado com o Resultado no Meu PC](https://github.com/chaos4455/Img2vid-Br-Front-End/raw/main/assets/generdated.mp4)

*Este vÃ­deo foi gerado no meu prÃ³prio PC utilizando o modelo img2vid da Stability AI. Ele demonstra a capacidade do modelo de transformar imagens estÃ¡ticas em vÃ­deos dinÃ¢micos.*

## ğŸ¥ VÃ­deo com VariaÃ§Ã£o nos Frames (MÃ­nimo de 6 Frames)

![VÃ­deo com VariaÃ§Ã£o nos Frames](https://github.com/chaos4455/Img2vid-Br-Front-End/raw/main/assets/generated_20240826_044207_ddc6fad9d9da4ee8898a241423f164d9.mp4)

*Este vÃ­deo mostra uma variaÃ§Ã£o nos frames, o que proporciona uma fluidez mÃ­nima ao vÃ­deo. Recomenda-se o uso de pelo menos 6 frames para garantir uma animaÃ§Ã£o suave.*

## ğŸ¥ Outro VÃ­deo Gerado no Meu Computador

![Outro VÃ­deo Gerado no Meu Computador](https://github.com/chaos4455/Img2vid-Br-Front-End/raw/main/assets/generated01.mp4)

*Mais um exemplo de vÃ­deo gerado utilizando a ferramenta, demonstrando a capacidade do modelo em produzir diferentes animaÃ§Ãµes a partir de entradas variadas.*



# ğŸ¯ Objetivo do Projeto

Este projeto nÃ£o Ã© apenas uma ferramenta, mas um **exemplo prÃ¡tico** de como a **IA generativa** pode ser utilizada para transformar **imagens estÃ¡ticas** em **vÃ­deos dinÃ¢micos**. Ele foi projetado para **entusiastas** e **profissionais** que desejam explorar as possibilidades de IA generativa **sem complicaÃ§Ãµes tÃ©cnicas**.

Desenvolver este **front-end** foi um desafio interessante e gratificante, e espero que vocÃª aproveite tanto quanto eu ao usÃ¡-lo! ğŸ‰

---

# ğŸŒ PortfÃ³lio & Contato

Sou um especialista em **IA generativa avanÃ§ada** e sempre busco novos desafios e oportunidades de aprendizado. VocÃª pode conferir mais sobre meu trabalho e projetos em andamento nos links abaixo:

- **LinkedIn**: [Elias Andrade](https://www.linkedin.com/in/itilmgf/)
- **GitHub**: [Meu RepositÃ³rio](https://github.com/chaos4455/)

---

# ğŸš€ Vamos Criar Algo IncrÃ­vel Juntos!

Se vocÃª estÃ¡ interessado em **IA generativa** e quer explorar mais, **nÃ£o hesite em me contatar** no meu linkedinğŸŒŸ

**Vamos juntos descobrir ainda mais aplicaÃ§Ãµes pra tecnologias de IA generativa!** ğŸ’ªğŸ¥âœ¨

MaringÃ¡ 26 08 2024 - Elias Andrade
